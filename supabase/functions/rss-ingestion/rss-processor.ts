// ==========================================
// RSS è™•ç†é‚è¼¯
// ==========================================

import Parser from "npm:rss-parser@3.13.0";
import type { FeedSource, RssArticle, ProcessingResult } from "./types.ts";
import { CONFIG } from "./config.ts";
import { decodeHtmlEntities, chunkArray, sleep } from "./utils.ts";
import { 
  extractLabels, 
  inferCategory, 
  processHackerNewsEntry, 
  getImageUrl 
} from "./processors.ts";
import { storeArticle } from "./database.ts";

// è™•ç†å–®å€‹è³‡æ–™æº
export async function processSingleSource(source: FeedSource, supabase: any): Promise<{
  processed: number;
  stored: number;
  skipped: number;
  errors: string[];
}> {
  const result = {
    processed: 0,
    stored: 0,
    skipped: 0,
    errors: []
  };

  try {
    console.log(`ğŸ”„ Processing ${source.name} (${source.type})`);
    const startTime = Date.now();
    
    const parser = new Parser();
    const feed = await parser.parseURL(source.url);
    const items = (feed.items || []).slice(0, CONFIG.MAX_ARTICLES_PER_FEED);

    console.log(`ğŸ“¥ Found ${items.length} items from ${source.name}`);

    // è™•ç†æ¯å€‹æ–‡ç« é …ç›®
    for (const item of items) {
      result.processed++;

      try {
        // Hacker News ç‰¹æ®Šè™•ç†
        const hnData = source.type === 'hackernews' ? 
          processHackerNewsEntry(item, source) : null;

        // æå–åœ–ç‰‡ (æ ¹æ“šå„ªå…ˆç´šæ±ºå®šæ˜¯å¦ç²å–)
        const imageUrl = await getImageUrl(item, source);

        // å°æ–¼ä½å„ªå…ˆç´šæºï¼Œå¦‚æœæ²’æœ‰åœ–ç‰‡å°±è·³é
        if (source.priority >= 3 && (!imageUrl || !imageUrl.startsWith("http"))) {
          console.log(`â­ï¸  Skipping low-priority article without image: ${item.title?.substring(0, 50)}...`);
          result.skipped++;
          continue;
        }

        // è§£ç¢¼æ–‡æœ¬
        const title = decodeHtmlEntities(item.title || "Untitled");
        const description = decodeHtmlEntities(
          item.contentSnippet || item.summary || item.description || ""
        );

        // æå–æ¨™ç±¤
        let labels = extractLabels(title, description);
        
        // æ·»åŠ  Hacker News ç‰¹æ®Šæ¨™ç±¤
        if (hnData?.specialLabels) {
          labels = [...labels, ...hnData.specialLabels];
        }

        // æ¨æ–·åˆ†é¡
        const category = inferCategory(item, source);

        // æ§‹å»ºæ–‡ç« å°è±¡
        const article: RssArticle = {
          article_id:
            item.guid ||
            item.id ||
            item.link ||
            `${source.url}#${title}`,
          title,
          description: description.substring(0, 500),
          content: description.substring(0, 1000),
          url: item.link || source.url,
          image_url: imageUrl,
          source: source.name,
          category,
          published_at:
            item.isoDate || item.pubDate || new Date().toISOString(),
        };

        // å­˜å„²æ–‡ç« 
        const stored = await storeArticle(supabase, article, labels);
        if (stored) {
          result.stored++;
        } else {
          result.skipped++;
        }
      } catch (itemError: any) {
        console.error(`âŒ Error processing item from ${source.name}:`, itemError.message);
        result.errors.push(`${source.name} - Item: ${itemError.message}`);
      }
    }

    const duration = Date.now() - startTime;
    console.log(`âœ… Completed ${source.name} in ${duration}ms - Processed: ${result.processed}, Stored: ${result.stored}, Skipped: ${result.skipped}`);

  } catch (feedError: any) {
    console.error(`âŒ Error processing feed ${source.name}:`, feedError.message);
    result.errors.push(`${source.name}: ${feedError.message}`);
  }

  return result;
}

// ä¸»è™•ç†å‡½æ•¸ - åˆ†æ‰¹è™•ç†
export async function processRssFeeds(supabase: any): Promise<ProcessingResult> {
  const totalResult: ProcessingResult = {
    processed: 0,
    stored: 0,
    skipped: 0,
    errors: [],
  };

  console.log(`ğŸš€ Starting RSS ingestion with ${CONFIG.BATCH_SIZE} batch size`);
  const overallStartTime = Date.now();

  // å¾é…ç½®ä¸­ç²å–æºä¸¦æŒ‰å„ªå…ˆç´šæ’åº
  const { RSS_FEEDS } = await import("./config.ts");
  const sortedSources = [...RSS_FEEDS].sort((a, b) => a.priority - b.priority);
  
  // åˆ†æ‰¹è™•ç†
  const batches = chunkArray(sortedSources, CONFIG.BATCH_SIZE);
  console.log(`ğŸ“¦ Processing ${batches.length} batches of ${CONFIG.BATCH_SIZE} sources each`);

  for (let i = 0; i < batches.length; i++) {
    const batch = batches[i];
    console.log(`\nğŸ”„ Processing batch ${i + 1}/${batches.length}`);
    
    // ä¸¦è¡Œè™•ç†æ‰¹æ¬¡ä¸­çš„æº
    const batchPromises = batch.map(source => processSingleSource(source, supabase));
    const batchResults = await Promise.allSettled(batchPromises);
    
    // åˆä½µçµæœ
    batchResults.forEach((result, index) => {
      if (result.status === 'fulfilled') {
        const sourceResult = result.value;
        totalResult.processed += sourceResult.processed;
        totalResult.stored += sourceResult.stored;
        totalResult.skipped += sourceResult.skipped;
        totalResult.errors.push(...sourceResult.errors);
      } else {
        const sourceName = batch[index].name;
        console.error(`âŒ Batch processing failed for ${sourceName}:`, result.reason);
        totalResult.errors.push(`${sourceName}: Batch processing failed - ${result.reason}`);
      }
    });
    
    // æ‰¹æ¬¡é–“å»¶é² (é™¤äº†æœ€å¾Œä¸€æ‰¹)
    if (i < batches.length - 1) {
      console.log(`â³ Waiting ${CONFIG.BATCH_DELAY}ms before next batch...`);
      await sleep(CONFIG.BATCH_DELAY);
    }
  }

  const totalDuration = Date.now() - overallStartTime;
  console.log(`\nğŸ‰ RSS ingestion completed in ${totalDuration}ms`);
  console.log(`ğŸ“Š Final stats - Processed: ${totalResult.processed}, Stored: ${totalResult.stored}, Skipped: ${totalResult.skipped}, Errors: ${totalResult.errors.length}`);

  return totalResult;
}
